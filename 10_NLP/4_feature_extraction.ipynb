{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "xw5DUwWgZ9bk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "GdjXXLfwUyoq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'text':['people watch campusx', 'campusx watch campusx', 'people write comment', 'campusx write comment'], 'output': [1, 1, 0, 0]})"
      ],
      "metadata": {
        "id": "sq7TYPawU38p"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "x4jIbITkVLyg",
        "outputId": "5ddc302a-4af6-4562-d073-5bc67e81393e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    text  output\n",
              "0   people watch campusx       1\n",
              "1  campusx watch campusx       1\n",
              "2   people write comment       0\n",
              "3  campusx write comment       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f6700941-7001-45bb-b886-f8845efe2d6a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>people watch campusx</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>campusx watch campusx</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>people write comment</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>campusx write comment</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f6700941-7001-45bb-b886-f8845efe2d6a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f6700941-7001-45bb-b886-f8845efe2d6a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f6700941-7001-45bb-b886-f8845efe2d6a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-61e9ef4b-8bfb-41bc-ad06-6e69979a3042\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-61e9ef4b-8bfb-41bc-ad06-6e69979a3042')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-61e9ef4b-8bfb-41bc-ad06-6e69979a3042 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_6bbc5b1f-fefa-4cfa-97cf-0476a63dda71\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6bbc5b1f-fefa-4cfa-97cf-0476a63dda71 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"campusx watch campusx\",\n          \"campusx write comment\",\n          \"people watch campusx\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bag of words"
      ],
      "metadata": {
        "id": "LX0Aa-9hZ_En"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "43i1Dhk6VMZh"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv = CountVectorizer()"
      ],
      "metadata": {
        "id": "f7ZnUkJzVRfj"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bow = cv.fit_transform(df.text)"
      ],
      "metadata": {
        "id": "eBWGdWCAVTBT"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cv.vocabulary_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdLtUqDJVq3S",
        "outputId": "da853579-685c-4e7d-b5c1-c22b277a93a3"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'people': 2, 'watch': 3, 'campusx': 0, 'write': 4, 'comment': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The vector representation of '{df.text[0]}' is: \\n\",bow[0].toarray()[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGciHZ3XVt8M",
        "outputId": "c122b65c-14f4-4846-cfcf-3cd50c3b77b0"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The vector representation of 'people watch campusx' is: \n",
            " [1 0 1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The vector representation of '{df.text[1]}' is: \\n\", bow[1].toarray()[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKnKV_AmV6jB",
        "outputId": "61fe54ce-c852-4357-9b49-aab9be2436cc"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The vector representation of 'campusx watch campusx' is: \n",
            " [2 0 0 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv.transform([\"campusx watch and campus write comment\"]).toarray()[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ml3YF5q3WhgF",
        "outputId": "e44e293a-c129-49ae-9307-5dfb7fbd5ee1"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## N-grams"
      ],
      "metadata": {
        "id": "fRdvJEsRaBN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bi-grams\n",
        "bi_gram_cv = CountVectorizer(ngram_range = (2,2))"
      ],
      "metadata": {
        "id": "TEBJLAlYWzjt"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bi_gram_cv.fit_transform(df.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64DPrvjJasx7",
        "outputId": "6ba3c591-205f-4fea-8e2f-13ad2a73901a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<4x6 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 8 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bi_gram_cv.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRuEPkfMax69",
        "outputId": "57169c61-ba3f-48d0-bfc9-b8b966e66f2d"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'people watch': 2,\n",
              " 'watch campusx': 4,\n",
              " 'campusx watch': 0,\n",
              " 'people write': 3,\n",
              " 'write comment': 5,\n",
              " 'campusx write': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Both unigram and bigram\n",
        "uni_bi_cv = CountVectorizer(ngram_range = (1,2))"
      ],
      "metadata": {
        "id": "QjRWZG06a4HD"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bo_bi = uni_bi_cv.fit_transform(df.text)"
      ],
      "metadata": {
        "id": "uMvi4Y0JbBD6"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uni_bi_cv.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b30eMrBKbDQT",
        "outputId": "70e2ab67-afd3-4b79-9204-9b478f01116f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'people': 4,\n",
              " 'watch': 7,\n",
              " 'campusx': 0,\n",
              " 'people watch': 5,\n",
              " 'watch campusx': 8,\n",
              " 'campusx watch': 1,\n",
              " 'write': 9,\n",
              " 'comment': 3,\n",
              " 'people write': 6,\n",
              " 'write comment': 10,\n",
              " 'campusx write': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bo_bi[0].toarray()[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GP2bjr2bE_l",
        "outputId": "0009d1e4-4930-498f-f57e-f4e7c55f8575"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The vector representation of '{df.text[0]}' in bag of bi-grams is: \\n\", bo_bi[0].toarray()[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7z1Pl84bTLV",
        "outputId": "92a13b64-a541-44c7-ee33-d241a81bc778"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The vector representation of 'people watch campusx' in bag of bi-grams is: \n",
            " [1 0 0 0 1 1 0 1 1 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tf-Idf"
      ],
      "metadata": {
        "id": "9olDNWjhfKJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "PojjjmM7bgHp"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer()"
      ],
      "metadata": {
        "id": "_rt0feNKfRLg"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf.fit_transform(df.text).toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzxGAZn6fTuu",
        "outputId": "926dcaf3-bbcc-4d2b-9e71-0f674b5c3a03"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.49681612, 0.        , 0.61366674, 0.61366674, 0.        ],\n",
              "       [0.8508161 , 0.        , 0.        , 0.52546357, 0.        ],\n",
              "       [0.        , 0.57735027, 0.57735027, 0.        , 0.57735027],\n",
              "       [0.49681612, 0.61366674, 0.        , 0.        , 0.61366674]])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf.idf_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JafgBiAAfao8",
        "outputId": "b8809cd8-1329-419a-c21c-bb05447742c6"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.22314355, 1.51082562, 1.51082562, 1.51082562, 1.51082562])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf.get_feature_names_out()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikGHazopfo3C",
        "outputId": "29790b24-1e85-4f95-9d19-49325a007cdb"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['campusx', 'comment', 'people', 'watch', 'write'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The vector representation of '{df.text[0]}' in tf-idf is: \\n\", tfidf.transform(df.text).toarray()[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUTbW9ZVf0Ve",
        "outputId": "dbc75f0a-73b5-42bd-a551-980b70780fcd"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The vector representation of 'people watch campusx' in tf-idf is: \n",
            " [0.49681612 0.         0.61366674 0.61366674 0.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(TfidfVectorizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBX1htN-f9nc",
        "outputId": "9a270cbf-62e8-49a4-c946-ad9793f963d2"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class TfidfVectorizer in module sklearn.feature_extraction.text:\n",
            "\n",
            "class TfidfVectorizer(CountVectorizer)\n",
            " |  TfidfVectorizer(*, input='content', encoding='utf-8', decode_error='strict', strip_accents=None, lowercase=True, preprocessor=None, tokenizer=None, analyzer='word', stop_words=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', ngram_range=(1, 1), max_df=1.0, min_df=1, max_features=None, vocabulary=None, binary=False, dtype=<class 'numpy.float64'>, norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False)\n",
            " |  \n",
            " |  Convert a collection of raw documents to a matrix of TF-IDF features.\n",
            " |  \n",
            " |  Equivalent to :class:`CountVectorizer` followed by\n",
            " |  :class:`TfidfTransformer`.\n",
            " |  \n",
            " |  For an example of usage, see\n",
            " |  :ref:`sphx_glr_auto_examples_text_plot_document_classification_20newsgroups.py`.\n",
            " |  \n",
            " |  For an efficiency comparison of the different feature extractors, see\n",
            " |  :ref:`sphx_glr_auto_examples_text_plot_hashing_vs_dict_vectorizer.py`.\n",
            " |  \n",
            " |  For an example of document clustering and comparison with\n",
            " |  :class:`~sklearn.feature_extraction.text.HashingVectorizer`, see\n",
            " |  :ref:`sphx_glr_auto_examples_text_plot_document_clustering.py`.\n",
            " |  \n",
            " |  Read more in the :ref:`User Guide <text_feature_extraction>`.\n",
            " |  \n",
            " |  Parameters\n",
            " |  ----------\n",
            " |  input : {'filename', 'file', 'content'}, default='content'\n",
            " |      - If `'filename'`, the sequence passed as an argument to fit is\n",
            " |        expected to be a list of filenames that need reading to fetch\n",
            " |        the raw content to analyze.\n",
            " |  \n",
            " |      - If `'file'`, the sequence items must have a 'read' method (file-like\n",
            " |        object) that is called to fetch the bytes in memory.\n",
            " |  \n",
            " |      - If `'content'`, the input is expected to be a sequence of items that\n",
            " |        can be of type string or byte.\n",
            " |  \n",
            " |  encoding : str, default='utf-8'\n",
            " |      If bytes or files are given to analyze, this encoding is used to\n",
            " |      decode.\n",
            " |  \n",
            " |  decode_error : {'strict', 'ignore', 'replace'}, default='strict'\n",
            " |      Instruction on what to do if a byte sequence is given to analyze that\n",
            " |      contains characters not of the given `encoding`. By default, it is\n",
            " |      'strict', meaning that a UnicodeDecodeError will be raised. Other\n",
            " |      values are 'ignore' and 'replace'.\n",
            " |  \n",
            " |  strip_accents : {'ascii', 'unicode'} or callable, default=None\n",
            " |      Remove accents and perform other character normalization\n",
            " |      during the preprocessing step.\n",
            " |      'ascii' is a fast method that only works on characters that have\n",
            " |      a direct ASCII mapping.\n",
            " |      'unicode' is a slightly slower method that works on any characters.\n",
            " |      None (default) means no character normalization is performed.\n",
            " |  \n",
            " |      Both 'ascii' and 'unicode' use NFKD normalization from\n",
            " |      :func:`unicodedata.normalize`.\n",
            " |  \n",
            " |  lowercase : bool, default=True\n",
            " |      Convert all characters to lowercase before tokenizing.\n",
            " |  \n",
            " |  preprocessor : callable, default=None\n",
            " |      Override the preprocessing (string transformation) stage while\n",
            " |      preserving the tokenizing and n-grams generation steps.\n",
            " |      Only applies if ``analyzer`` is not callable.\n",
            " |  \n",
            " |  tokenizer : callable, default=None\n",
            " |      Override the string tokenization step while preserving the\n",
            " |      preprocessing and n-grams generation steps.\n",
            " |      Only applies if ``analyzer == 'word'``.\n",
            " |  \n",
            " |  analyzer : {'word', 'char', 'char_wb'} or callable, default='word'\n",
            " |      Whether the feature should be made of word or character n-grams.\n",
            " |      Option 'char_wb' creates character n-grams only from text inside\n",
            " |      word boundaries; n-grams at the edges of words are padded with space.\n",
            " |  \n",
            " |      If a callable is passed it is used to extract the sequence of features\n",
            " |      out of the raw, unprocessed input.\n",
            " |  \n",
            " |      .. versionchanged:: 0.21\n",
            " |          Since v0.21, if ``input`` is ``'filename'`` or ``'file'``, the data\n",
            " |          is first read from the file and then passed to the given callable\n",
            " |          analyzer.\n",
            " |  \n",
            " |  stop_words : {'english'}, list, default=None\n",
            " |      If a string, it is passed to _check_stop_list and the appropriate stop\n",
            " |      list is returned. 'english' is currently the only supported string\n",
            " |      value.\n",
            " |      There are several known issues with 'english' and you should\n",
            " |      consider an alternative (see :ref:`stop_words`).\n",
            " |  \n",
            " |      If a list, that list is assumed to contain stop words, all of which\n",
            " |      will be removed from the resulting tokens.\n",
            " |      Only applies if ``analyzer == 'word'``.\n",
            " |  \n",
            " |      If None, no stop words will be used. In this case, setting `max_df`\n",
            " |      to a higher value, such as in the range (0.7, 1.0), can automatically detect\n",
            " |      and filter stop words based on intra corpus document frequency of terms.\n",
            " |  \n",
            " |  token_pattern : str, default=r\"(?u)\\\\b\\\\w\\\\w+\\\\b\"\n",
            " |      Regular expression denoting what constitutes a \"token\", only used\n",
            " |      if ``analyzer == 'word'``. The default regexp selects tokens of 2\n",
            " |      or more alphanumeric characters (punctuation is completely ignored\n",
            " |      and always treated as a token separator).\n",
            " |  \n",
            " |      If there is a capturing group in token_pattern then the\n",
            " |      captured group content, not the entire match, becomes the token.\n",
            " |      At most one capturing group is permitted.\n",
            " |  \n",
            " |  ngram_range : tuple (min_n, max_n), default=(1, 1)\n",
            " |      The lower and upper boundary of the range of n-values for different\n",
            " |      n-grams to be extracted. All values of n such that min_n <= n <= max_n\n",
            " |      will be used. For example an ``ngram_range`` of ``(1, 1)`` means only\n",
            " |      unigrams, ``(1, 2)`` means unigrams and bigrams, and ``(2, 2)`` means\n",
            " |      only bigrams.\n",
            " |      Only applies if ``analyzer`` is not callable.\n",
            " |  \n",
            " |  max_df : float or int, default=1.0\n",
            " |      When building the vocabulary ignore terms that have a document\n",
            " |      frequency strictly higher than the given threshold (corpus-specific\n",
            " |      stop words).\n",
            " |      If float in range [0.0, 1.0], the parameter represents a proportion of\n",
            " |      documents, integer absolute counts.\n",
            " |      This parameter is ignored if vocabulary is not None.\n",
            " |  \n",
            " |  min_df : float or int, default=1\n",
            " |      When building the vocabulary ignore terms that have a document\n",
            " |      frequency strictly lower than the given threshold. This value is also\n",
            " |      called cut-off in the literature.\n",
            " |      If float in range of [0.0, 1.0], the parameter represents a proportion\n",
            " |      of documents, integer absolute counts.\n",
            " |      This parameter is ignored if vocabulary is not None.\n",
            " |  \n",
            " |  max_features : int, default=None\n",
            " |      If not None, build a vocabulary that only consider the top\n",
            " |      `max_features` ordered by term frequency across the corpus.\n",
            " |      Otherwise, all features are used.\n",
            " |  \n",
            " |      This parameter is ignored if vocabulary is not None.\n",
            " |  \n",
            " |  vocabulary : Mapping or iterable, default=None\n",
            " |      Either a Mapping (e.g., a dict) where keys are terms and values are\n",
            " |      indices in the feature matrix, or an iterable over terms. If not\n",
            " |      given, a vocabulary is determined from the input documents.\n",
            " |  \n",
            " |  binary : bool, default=False\n",
            " |      If True, all non-zero term counts are set to 1. This does not mean\n",
            " |      outputs will have only 0/1 values, only that the tf term in tf-idf\n",
            " |      is binary. (Set `binary` to True, `use_idf` to False and\n",
            " |      `norm` to None to get 0/1 outputs).\n",
            " |  \n",
            " |  dtype : dtype, default=float64\n",
            " |      Type of the matrix returned by fit_transform() or transform().\n",
            " |  \n",
            " |  norm : {'l1', 'l2'} or None, default='l2'\n",
            " |      Each output row will have unit norm, either:\n",
            " |  \n",
            " |      - 'l2': Sum of squares of vector elements is 1. The cosine\n",
            " |        similarity between two vectors is their dot product when l2 norm has\n",
            " |        been applied.\n",
            " |      - 'l1': Sum of absolute values of vector elements is 1.\n",
            " |        See :func:`~sklearn.preprocessing.normalize`.\n",
            " |      - None: No normalization.\n",
            " |  \n",
            " |  use_idf : bool, default=True\n",
            " |      Enable inverse-document-frequency reweighting. If False, idf(t) = 1.\n",
            " |  \n",
            " |  smooth_idf : bool, default=True\n",
            " |      Smooth idf weights by adding one to document frequencies, as if an\n",
            " |      extra document was seen containing every term in the collection\n",
            " |      exactly once. Prevents zero divisions.\n",
            " |  \n",
            " |  sublinear_tf : bool, default=False\n",
            " |      Apply sublinear tf scaling, i.e. replace tf with 1 + log(tf).\n",
            " |  \n",
            " |  Attributes\n",
            " |  ----------\n",
            " |  vocabulary_ : dict\n",
            " |      A mapping of terms to feature indices.\n",
            " |  \n",
            " |  fixed_vocabulary_ : bool\n",
            " |      True if a fixed vocabulary of term to indices mapping\n",
            " |      is provided by the user.\n",
            " |  \n",
            " |  idf_ : array of shape (n_features,)\n",
            " |      The inverse document frequency (IDF) vector; only defined\n",
            " |      if ``use_idf`` is True.\n",
            " |  \n",
            " |  See Also\n",
            " |  --------\n",
            " |  CountVectorizer : Transforms text into a sparse matrix of n-gram counts.\n",
            " |  \n",
            " |  TfidfTransformer : Performs the TF-IDF transformation from a provided\n",
            " |      matrix of counts.\n",
            " |  \n",
            " |  Examples\n",
            " |  --------\n",
            " |  >>> from sklearn.feature_extraction.text import TfidfVectorizer\n",
            " |  >>> corpus = [\n",
            " |  ...     'This is the first document.',\n",
            " |  ...     'This document is the second document.',\n",
            " |  ...     'And this is the third one.',\n",
            " |  ...     'Is this the first document?',\n",
            " |  ... ]\n",
            " |  >>> vectorizer = TfidfVectorizer()\n",
            " |  >>> X = vectorizer.fit_transform(corpus)\n",
            " |  >>> vectorizer.get_feature_names_out()\n",
            " |  array(['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third',\n",
            " |         'this'], ...)\n",
            " |  >>> print(X.shape)\n",
            " |  (4, 9)\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      TfidfVectorizer\n",
            " |      CountVectorizer\n",
            " |      _VectorizerMixin\n",
            " |      sklearn.base.BaseEstimator\n",
            " |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
            " |      sklearn.utils._metadata_requests._MetadataRequester\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, *, input='content', encoding='utf-8', decode_error='strict', strip_accents=None, lowercase=True, preprocessor=None, tokenizer=None, analyzer='word', stop_words=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', ngram_range=(1, 1), max_df=1.0, min_df=1, max_features=None, vocabulary=None, binary=False, dtype=<class 'numpy.float64'>, norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  fit(self, raw_documents, y=None)\n",
            " |      Learn vocabulary and idf from training set.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      raw_documents : iterable\n",
            " |          An iterable which generates either str, unicode or file objects.\n",
            " |      \n",
            " |      y : None\n",
            " |          This parameter is not needed to compute tfidf.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : object\n",
            " |          Fitted vectorizer.\n",
            " |  \n",
            " |  fit_transform(self, raw_documents, y=None)\n",
            " |      Learn vocabulary and idf, return document-term matrix.\n",
            " |      \n",
            " |      This is equivalent to fit followed by transform, but more efficiently\n",
            " |      implemented.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      raw_documents : iterable\n",
            " |          An iterable which generates either str, unicode or file objects.\n",
            " |      \n",
            " |      y : None\n",
            " |          This parameter is ignored.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      X : sparse matrix of (n_samples, n_features)\n",
            " |          Tf-idf-weighted document-term matrix.\n",
            " |  \n",
            " |  set_fit_request(self: sklearn.feature_extraction.text.TfidfVectorizer, *, raw_documents: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.feature_extraction.text.TfidfVectorizer\n",
            " |      Request metadata passed to the ``fit`` method.\n",
            " |      \n",
            " |      Note that this method is only relevant if\n",
            " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
            " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
            " |      mechanism works.\n",
            " |      \n",
            " |      The options for each parameter are:\n",
            " |      \n",
            " |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
            " |      \n",
            " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
            " |      \n",
            " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
            " |      \n",
            " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
            " |      \n",
            " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
            " |      existing request. This allows you to change the request for some\n",
            " |      parameters and not others.\n",
            " |      \n",
            " |      .. versionadded:: 1.3\n",
            " |      \n",
            " |      .. note::\n",
            " |          This method is only relevant if this estimator is used as a\n",
            " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
            " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      raw_documents : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            " |          Metadata routing for ``raw_documents`` parameter in ``fit``.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : object\n",
            " |          The updated object.\n",
            " |  \n",
            " |  set_transform_request(self: sklearn.feature_extraction.text.TfidfVectorizer, *, raw_documents: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.feature_extraction.text.TfidfVectorizer\n",
            " |      Request metadata passed to the ``transform`` method.\n",
            " |      \n",
            " |      Note that this method is only relevant if\n",
            " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
            " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
            " |      mechanism works.\n",
            " |      \n",
            " |      The options for each parameter are:\n",
            " |      \n",
            " |      - ``True``: metadata is requested, and passed to ``transform`` if provided. The request is ignored if metadata is not provided.\n",
            " |      \n",
            " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``transform``.\n",
            " |      \n",
            " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
            " |      \n",
            " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
            " |      \n",
            " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
            " |      existing request. This allows you to change the request for some\n",
            " |      parameters and not others.\n",
            " |      \n",
            " |      .. versionadded:: 1.3\n",
            " |      \n",
            " |      .. note::\n",
            " |          This method is only relevant if this estimator is used as a\n",
            " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
            " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      raw_documents : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            " |          Metadata routing for ``raw_documents`` parameter in ``transform``.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : object\n",
            " |          The updated object.\n",
            " |  \n",
            " |  transform(self, raw_documents)\n",
            " |      Transform documents to document-term matrix.\n",
            " |      \n",
            " |      Uses the vocabulary and document frequencies (df) learned by fit (or\n",
            " |      fit_transform).\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      raw_documents : iterable\n",
            " |          An iterable which generates either str, unicode or file objects.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      X : sparse matrix of (n_samples, n_features)\n",
            " |          Tf-idf-weighted document-term matrix.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors defined here:\n",
            " |  \n",
            " |  idf_\n",
            " |      Inverse document frequency vector, only defined if `use_idf=True`.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      ndarray of shape (n_features,)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from CountVectorizer:\n",
            " |  \n",
            " |  get_feature_names_out(self, input_features=None)\n",
            " |      Get output feature names for transformation.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      input_features : array-like of str or None, default=None\n",
            " |          Not used, present here for API consistency by convention.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      feature_names_out : ndarray of str objects\n",
            " |          Transformed feature names.\n",
            " |  \n",
            " |  inverse_transform(self, X)\n",
            " |      Return terms per document with nonzero entries in X.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
            " |          Document-term matrix.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      X_inv : list of arrays of shape (n_samples,)\n",
            " |          List of arrays of terms.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from _VectorizerMixin:\n",
            " |  \n",
            " |  build_analyzer(self)\n",
            " |      Return a callable to process input data.\n",
            " |      \n",
            " |      The callable handles preprocessing, tokenization, and n-grams generation.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      analyzer: callable\n",
            " |          A function to handle preprocessing, tokenization\n",
            " |          and n-grams generation.\n",
            " |  \n",
            " |  build_preprocessor(self)\n",
            " |      Return a function to preprocess the text before tokenization.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      preprocessor: callable\n",
            " |            A function to preprocess the text before tokenization.\n",
            " |  \n",
            " |  build_tokenizer(self)\n",
            " |      Return a function that splits a string into a sequence of tokens.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      tokenizer: callable\n",
            " |            A function to split a string into a sequence of tokens.\n",
            " |  \n",
            " |  decode(self, doc)\n",
            " |      Decode the input into a string of unicode symbols.\n",
            " |      \n",
            " |      The decoding strategy depends on the vectorizer parameters.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      doc : bytes or str\n",
            " |          The string to decode.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      doc: str\n",
            " |          A string of unicode symbols.\n",
            " |  \n",
            " |  get_stop_words(self)\n",
            " |      Build or fetch the effective stop words list.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      stop_words: list or None\n",
            " |              A list of stop words.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from _VectorizerMixin:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.BaseEstimator:\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |  \n",
            " |  __repr__(self, N_CHAR_MAX=700)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  __sklearn_clone__(self)\n",
            " |  \n",
            " |  get_params(self, deep=True)\n",
            " |      Get parameters for this estimator.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      deep : bool, default=True\n",
            " |          If True, will return the parameters for this estimator and\n",
            " |          contained subobjects that are estimators.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      params : dict\n",
            " |          Parameter names mapped to their values.\n",
            " |  \n",
            " |  set_params(self, **params)\n",
            " |      Set the parameters of this estimator.\n",
            " |      \n",
            " |      The method works on simple estimators as well as on nested objects\n",
            " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
            " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
            " |      possible to update each component of a nested object.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      **params : dict\n",
            " |          Estimator parameters.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : estimator instance\n",
            " |          Estimator instance.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
            " |  \n",
            " |  get_metadata_routing(self)\n",
            " |      Get metadata routing of this object.\n",
            " |      \n",
            " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
            " |      mechanism works.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      routing : MetadataRequest\n",
            " |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
            " |          routing information.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
            " |  \n",
            " |  __init_subclass__(**kwargs) from builtins.type\n",
            " |      Set the ``set_{method}_request`` methods.\n",
            " |      \n",
            " |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
            " |      looks for the information available in the set default values which are\n",
            " |      set using ``__metadata_request__*`` class attributes, or inferred\n",
            " |      from method signatures.\n",
            " |      \n",
            " |      The ``__metadata_request__*`` class attributes are used when a method\n",
            " |      does not explicitly accept a metadata through its arguments or if the\n",
            " |      developer would like to specify a request value for those metadata\n",
            " |      which are different from the default ``None``.\n",
            " |      \n",
            " |      References\n",
            " |      ----------\n",
            " |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jlvpgipngK5V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}